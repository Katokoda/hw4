\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage[T1]{fontenc}
\usepackage[english]{babel} % Importe deux langues et choisit la deuxième pour maintenant.
%\selectlanguage{english} % Permet de changer de langue au milieu du document.
\usepackage{lmodern}

\usepackage[framed,numbered,autolinebreaks,useliterate]{mcode}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
%\usepackage{parskip} 		%noindent
\usepackage{xfrac} 			%\sfrac{1}{2}
\usepackage{verbatim} 		% \begin{comment}
\usepackage{stackengine} 	% To define \circled later
\usepackage{enumitem}
\usepackage{cancel}			% \cancel{texte barré} %\bcancel, \xcancel


\usepackage{geometry}
\geometry{hmargin=2.3cm,vmargin=3cm}  % changer les marges \textbfhorizontales et verticales

\newcommand{\R}{\mathbb{R}}
\newcommand{\Rn}{\mathbb{R}^n}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathcal{E}}

\newcommand{\fl}{f_\lambda}
\newcommand{\dej}{\dfrac{\partial}{\partial x_j}}
\newcommand{\tp}{^\top}

\newcommand{\sump}{\sum_{i=1}^p}
\newcommand{\summ}{\sum_{i=1}^m}
\newcommand{\sumN}{\sum_{i=1}^N}
\newcommand{\x}{x_ {k+1}}
\newcommand{\e}{\eta_k}
\newcommand{\I}{\mathcal{I}}
\renewcommand{\Im}{\operatorname{Im}}
\newcommand{\T}{\text{T}}
\newcommand{\F}{\text{F}}
\newcommand{\fxy}{\dfrac{1}{2}x\tp A x + \dfrac{1}{2} y\tp B y}
\newcommand{\hxy}{\begin{bmatrix}
1-x\tp x\\
1-y\tp y\\
x\tp y
\end{bmatrix}}

\newcommand{\p}{\frac{\partial}{\partial x_i}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Homework 4 - Continuous Optimization}
\author{Estelle Baup, Samuel Bélisle, Cassandre Renaud }

\begin{document}
\maketitle

We want to solve the following problem:
\begin{equation*} \tag{P}\label{P}
\min_{x,y\in\R^n} f(x, y) \text{ subject to } h(x,y)=0,
\end{equation*}
where $f$ and $h$ are specified on the homework sheet.

\section*{Question 1}


The feasible set is $S=\{x,y \in \R^n \mid h(x,y)=0\}=\{x,y \in \R^n \mid 1-x\tp x=0,\ 1-y\tp y=0,\ x\tp y=0 \}$. \\
It is not convex. Indeed, we will give two points $z_1$ and $z_2$ $\in S$ such that $z=\lambda z_1 + (1-\lambda) z_2 \notin S$ for a given $\lambda\in ]0,1[$. We will work with $n=2$.\\


\noindent We will take $x_1 = \begin{pmatrix} 1\\ 0\end{pmatrix},\ y_1 = \begin{pmatrix} 0\\ 1\end{pmatrix}$ and write $z_1 = (x_1, y_1)$. First we check that $z_1 \in S$.
\begin{itemize}
\item $1-x_{1}\tp x_1=
1-
\begin{pmatrix} 1& 0\end{pmatrix}
\begin{pmatrix} 1\\ 0\end{pmatrix}
=1-1=0$
\item $1-y_{1}\tp y_1=
1-
\begin{pmatrix} 0& 1\end{pmatrix}
\begin{pmatrix} 0\\ 1\end{pmatrix}
=1-1=0$
\item $x_{1}\top y_1=
\begin{pmatrix} 1& 0\end{pmatrix}
\begin{pmatrix} 0\\ 1\end{pmatrix}
=0$
\end{itemize}
And we will take $z_2=(x_2,y_2)= \left(
\begin{pmatrix} 0\\ 1\end{pmatrix},
\begin{pmatrix} 1\\ 0\end{pmatrix}
\right)$. We also check that $z_2 \in S$.
\begin{itemize}
\item $1-x_{2}\tp x_2
=1-
\begin{pmatrix} 0& 1\end{pmatrix}
\begin{pmatrix} 0\\ 1\end{pmatrix}
=1-1=0$
\item $1-y_{2}\tp y_2
=1-
\begin{pmatrix} 1& 0\end{pmatrix}
\begin{pmatrix} 1\\ 0\end{pmatrix}
=1-1=0$
\item $x_{2}\tp y_2
=
\begin{pmatrix} 0& 1\end{pmatrix}
\begin{pmatrix} 1\\ 0\end{pmatrix}
=0$
\end{itemize}
Lastly, we will take $\lambda=\frac{1}{2}$. We can compute 
$$
z=\lambda z_1 + (1-\lambda) z_2
=\frac{1}{2}
\left(
	\begin{pmatrix} 1\\ 0\end{pmatrix},
	\begin{pmatrix} 0\\ 1\end{pmatrix}
\right)
+\frac{1}{2}
\left(
	\begin{pmatrix} 0\\ 1\end{pmatrix},
	\begin{pmatrix} 1\\ 0\end{pmatrix}
\right)
=
\left(
	\begin{pmatrix} \sfrac{1}{2}\\ \sfrac{1}{2}\end{pmatrix},
	\begin{pmatrix} \sfrac{1}{2}\\ \sfrac{1}{2}\end{pmatrix}
\right)
=(x,y)$$
But now, we have $x\tp y=
\begin{pmatrix} \frac{1}{2}& \frac{1}{2}\end{pmatrix}
\begin{pmatrix} \sfrac{1}{2}\\ \sfrac{1}{2}\end{pmatrix}
=(\frac{1}{2})^2+(\frac{1}{2})^2=\frac{1}{2} \neq 0$. So the third condition of our function $h$ does not hold at this point, hence $z\notin S$ and the set $S$ is not convex.\\

By definition, LICQ holds at $x\in S$ if and only if $\nabla h_1(x),\dots\nabla h_p(x)$, and $\nabla g_i(x)$ for $i\in \mathcal I(x) $ are linearly independant.\\
Here, we do not have any constraint function $g_i$ but we have three functions $h_i$:
\begin{itemize}
\item  $h_1(x,y)=1-x\tp x$
\item $h_2(x,y)=1-y\tp y$
\item $h_3(x,y)= x\tp y$
\end{itemize} 
If we compute their gradients, we get:

\begin{itemize}
\item  $\nabla_x h_1(x,y)=\nabla_x \left(1-x\tp x\right)= \nabla_x \left(1-\sum_{i=1}^n x_{i}^2 \right)=-2x$  and $\nabla_y h_1(x,y)=0$ \\

$\qquad$ then $\nabla h_1(x,y)=
\begin{bmatrix}
-2 x\\
\vec{0}
\end{bmatrix}
$ where $\vec{0}$ is the vector $\vec{0} \in \R^n$.
\item  $\nabla_x h_2(x,y)=0$ and $\nabla_y h_2(x,y)=\nabla_y \left(1-y\tp y\right)= \nabla_y \left(1-\sum_{i=1}^n y_{i}^2 \right)=-2 y$ \\

$\qquad$ then $\nabla h_2(x,y)=
\begin{bmatrix}
\vec{0}\\
-2y
\end{bmatrix}
$
\item $\nabla_x h_3(x,y)= \nabla_x \sum_{i=1}^n x_i \cdot y_i=y$ and  $\nabla_y h_3(x,y)= \nabla_y \sum_{i=1}^n x_i \cdot y_i= x$\\

$\qquad$ then $\nabla h_3(x,y)=$
$
\begin{bmatrix}
y\\
x
\end{bmatrix}
$
\end{itemize} 

\noindent We show that these three gradients are linearly independent:\\
$$\lambda_1 \nabla h_1(x,y)+\lambda_2\nabla h_2(x,y)+\lambda_3 \nabla h_3(x,y)=0 \iff \begin{cases}- 2 \lambda_1 x + \lambda_3 y=0\\ -2 \lambda_2 y+  \lambda_3 x=0\end{cases}$$ 

We have that this is true without having all the $\lambda_i=0$, if and only if $x=\lambda y$ (for some $\lambda\neq 0$ that can be deduced from the previous equations), or $y=0$. But if $y=0$, we have $h_2(x,y)=1\neq 0$ so our point is not feasible. Same with $h_1$ if $x=0$. Lastly, if $x=\lambda y$ for $\lambda\neq 0, x, y \neq 0$, we get that $h_3(x,y)=x\tp y=\lambda y\tp y=\lambda ||y||^2 \neq 0$, so our point is not feasible either.\\
To conclude, we get that for all of our feasible points, i.e. the points in the set $S$, $ \nabla h_1(x,y), \nabla h_2(x,y), \nabla h_3(x,y)$ are linearly independent, which means by definition that LICQ holds.

\section*{Question 2}

Our two first constraints $h_1(x,y)=1-x\tp x =0$ and $h_2(x,y)=1-y\tp y =0$ can be rephrased $||x||=||y||=1$.\\
We notice that there is no constraint on $x$ and $y$ at the same time, i.e. a constraint that tells us what $x$ must be related to $y$ and vice-versa. Similarly, we can notice that our target function doesn't have a part where $x$ and $y$ are mixed.\\
It means that if we optimized $x$ and $y$ separately, the optimum found will be the optimum for our relaxed problem as well. So we rewrite our relaxed problem as:
$$\min_{\substack{x\in \R^n\\ ||x||=1}}  \frac{1}{2} x\tp A x +\min_{\substack{y \in \R^n\\ ||y||=1}} \frac{1}{2} y\tp B y$$
The two problems are solved identically as the only thing changing is the matrix. To solve them, we first recall example 2.14 from the notes:\\
If $A$ is a symmetric linear map with eigenvalues $\lambda_1, ...,\lambda_n$, then $\forall u \in \mathcal{E}$, we have $$\lambda_{\min} ||u||^2 \leq \left< u, A(u)\right>\leq \lambda_{\max}||u||^2$$
and by rewriting the scalar product we get 
$$\lambda_{\min} ||u||^2 \leq u\tp A u \leq \lambda_{\max} ||u||^2$$
Applied to our problems (let's look at the first as they are similar), knowing that we optimize on vector of norm 1, we get that for every feasible $x$, we have
$$\frac{1}{2}\lambda_{\min}  \leq\frac{1}{2} x\tp A x \leq\frac{1}{2} \lambda_{\max} $$
It tells us that our optimal value can't be lower that $\frac{1}{2} \lambda_{\min}$. If we find an $x$ that attains this bound, we will know that it is the optimal value. So let's find it.\\
As $\lambda_{\min}$ is an eigenvalue, it means that $\exists v_{\min} \in \R^n, v_{\min} \neq 0$ such that $A v_{\min}=\lambda_{\min} v_{\min}$. We take $x=\frac{v_{\min}}{||v_{\min}||}$, which is feasible since it has norm 1, and then we have
$$x\tp A x =\frac{1}{||v_{\min}||^2} v_{\min}\tp \left( A v_{\min} \right)=\frac{1}{||v_{\min}||^2} v_{\min}\tp (\lambda_{\min} v_{\min})=\frac{\lambda_{\min}}{||v_{\min}||^2} v_{\min}\tp v_{\min}=\frac{\lambda_{\min}}{||v_{\min}||^2} \cdot ||v_{\min}||^2=\lambda_{\min}$$
Therefore our lower bound is attained for this $x$, which means it is the optimal value.\\
We denote $\lambda_{\min} (A)$ and $\lambda_{\min} (B)$ the minimal eigenvalues for the matrices $A$ and $B$. From our previous reasoning, we have that $\frac{\lambda_{\min} (A)}{2}$ and $\frac{\lambda_{\min} (B)}{2}$ are our optimal values, and so the optimal value for our relaxed problem is $\frac{\lambda_{\min} (A)+\lambda_{\min} (B)}{2}$.\\

%%TODO On devrait comparer avec le "target problem"// ez : c'est pas juste que ça nous donne une lower bound vu que le relaxed enlève une condition ?
Now, what does that say about our target problem?\\
Because our relaxed problem is our target problem minus a condition, we know its optimal value must be lower than the optimal value of the target problem, as every feasible solution of our target problem is feasible in our relaxed problem. Therefore, we can say that our target problem has a lower bound of $\frac{\lambda_{\min} (A)+\lambda_{\min} (B)}{2}$. However, we don't know (yet) if it is the optimal value or not.

\section*{Question 3}
Let's find an expression for the Lagrangian function $L(x,y,\mu)$. We denote $I_n$ for the identity matrix in $\R^{n\times n}$.
\begin{align*}
L(x,y,\mu) &= f(x,y)+\mu\tp h(x,y) \\
&=\fxy  + \begin{bmatrix} \mu_1 &\mu_2 & \mu_3 \end{bmatrix} \hxy \\
&=\fxy + \mu_1(1-x\tp x) +\mu_2(1-y\tp y) + \mu_3 x\tp y \\
&= \dfrac{1}{2}\left(x\tp A x - 2\mu_1 x\tp x +  y\tp B y -2\mu_2 y\tp y + 2\mu_3 x\tp y\right) + \mu_1+\mu_2 \\
&= \dfrac{1}{2} \left(x\tp  \left( A - 2\mu_1 I_n \right) x +  y\tp \left( B -2\mu_2 I_n \right) y   + x\tp  \left( \mu_3 I_n \right) y+ y\tp \left( \mu_3 I_n \right) x \right) + \mu_1+\mu_2 \\
&= \dfrac{1}{2} \begin{bmatrix} x\tp & y\tp\end{bmatrix}
\begin{bmatrix} A-2\mu_1 I_n & \mu_3 I_n \\
\mu_3 I_n & B-2\mu_2 I_n \end{bmatrix}
\begin{bmatrix} x \\ y \end{bmatrix} +\mu_1+\mu_2 
\end{align*}
As $A$ and $B$ are symmetric by assumptions, and $I_n$ is also symmetric, we see that the above matrix is symmetric.


\section*{Question 4}
By definition, $L_D(\mu)=\inf\limits_{x,y\in\R^n} L(x,y,\mu)$. Using the previous question, and denoting $M_\mu:=\begin{bmatrix} A-2\mu_1 I_n & \mu_3 I_n \\
\mu_3 I_n & B-2\mu_2 I_n \end{bmatrix}$, we find:
\begin{align*}
L_D(\mu)&=\inf\limits_{x,y\in\R^n} L(x,y,\mu) \\
&=\inf\limits_{x,y\in\R^n} \left\lbrace \dfrac{1}{2} \begin{bmatrix} x\tp & y\tp\end{bmatrix}M_\mu\begin{bmatrix} x \\ y \end{bmatrix} +\mu_1+\mu_2 \right\rbrace \\
&=\inf\limits_{x,y\in\R^n} \left\lbrace \dfrac{1}{2} \begin{bmatrix} x\tp & y\tp\end{bmatrix}M_\mu\begin{bmatrix} x \\ y \end{bmatrix} \right\rbrace+\mu_1+\mu_2   \\
&=\begin{cases} \mu_1+\mu_2 &\text{if }M_\mu\succeq 0 \\ -\infty &\text{otherwise} \end{cases}
\end{align*}
Because if we do not have $M_\mu\succeq 0 $, there exists a negative eigenvalue $\lambda$ and its associated eigenvector $v \in \R^{2n}$ (by simplicity we take v such that $||v||=1$) such that$ M_\mu v=\lambda v$, and so, $\forall n \in \N$, we have that $nv M_\mu nv=n^2 v \lambda v=n^2 \lambda$, so by taking the sequence $(nv)_{n \in \N}$, we have a sequence of vectors such that $L(v_x,v_y,\mu) \to \infty$ (where $v_x$ and $v_y$ described respectively the n first and n last coordinates of the vector).\\
Hence we can write the dual as:
\begin{equation*}\tag{D} \label{D}
\max_{\mu\in\R^3} \{\mu_1+\mu_2\} \quad \text{ subject to } \begin{bmatrix} A-2\mu_1 I_n & \mu_3 I_n \\
\mu_3 I_n & B-2\mu_2 I_n \end{bmatrix} \succeq 0
\end{equation*}

\section*{Question 5}
We know that $M_\mu$ is symmetric for all $\mu\in\R^3$. If $\mu$ is a solution of the dual problem, then the matrix $M_\mu$ associated with the values of $\mu$ should be positive semidefinite. This implies in particular that the diagonal blocks would be positive semidefinite too, i.e. $A-2\mu_1 I_n\succeq 0$ and $B-2\mu_2 I_n \succeq 0$. The two latter conditions are equivalent to $2\mu_1\leq \lambda_{\min} (A)$ and $2\mu_2\leq \lambda_{\min}(B)$, where  $\lambda_{\min} (A)$ and $\lambda_{\min} (B)$ are the smallest eigenvalues of $A$ and $B$ respectively.\\
Hence, if we focus only on satisfying the conditions  $A-2\mu_1 I_n\succeq 0$ and $B-2\mu_2 I_n \succeq 0$, the optimal value for \eqref{D} is $\frac{\lambda_{\min} (A)+\lambda_{\min} (B)}{2}$. \\
In fact, this is the optimal value even for the whole condition $M_\mu\succeq 0$. Indeed, let's focus on the relaxed problem for a bit. Call $P'$ the relaxed primal, and $D'$ the relaxed dual. By question 2, we know that $\frac{\lambda_{\min} (A)+\lambda_{\min} (B)}{2}$ is the lower bound on the optimal value for $P'$. Now observe that the relaxed  dual function is in fact $$L_{D'} (\mu)= \inf\limits_{x,y\in\R^n} \left\lbrace \dfrac{1}{2} \begin{bmatrix} x\tp & y\tp\end{bmatrix}\begin{bmatrix} A-2\mu_1 I_n & 0 \\
0 & B-2\mu_2 I_n \end{bmatrix}\begin{bmatrix} x \\ y \end{bmatrix} \right\rbrace+\mu_1+\mu_2, $$
This comes directly from the fact that if we remove the third constraint $h_3(x,y)=0$, then we no longer have any $\mu_3$. \\

By weak duality for the relaxed problem, and denoting $S'=\{(x,y)\mid h_1(x,y)=0, h_2(x,y)=0\}$ the feasible set of $P'$, we get:
$$\max_{\mu\in\R^3} L_{D'}(\mu)\leq \min_{(x,y)\in\R^n\times\R^n}L_{P'}(x,y) = \min_{(x,y)\in S'} f(x,y) = \dfrac{\lambda_{\min} (A)+\lambda_{\min} (B)}{2}$$
Moreover, we know $\max_{\mu\in\R^3} L_{D}(\mu)\leq \max_{\mu\in\R^3} L_{D'}(\mu)$ as if we go from $D'$ to $D$ we add a constraint, and the maximum can only go lower. Then putting this together with the previous equality gives:
$$\max_{\mu\in\R^3} L_{D}(\mu)\leq \dfrac{\lambda_{\min} (A)+\lambda_{\min} (B)}{2}$$

Finally, we see that taking $\mu^*=\left(\dfrac{\lambda_{\min} (A)}{2}, \dfrac{\lambda_{\min} (B)}{2}, 0\right)$ in the dual $D$ gives $M_{\mu^*}\succeq 0$ as both diagonal blocks will be positive semidefinite (and the anti-diagonal blocks are zero), and $L_D(\mu^*)=\dfrac{\lambda_{\min} (A)+\lambda_{\min} (B)}{2}$. So the upper bound is attained and is indeed the optimal value of the dual problem.


\section*{Question 6}
To use the strong duality theorem, we need to satisfy the two following assumptions:
\begin{align*}
(\text{A}1) &  \text{ the primal problem \eqref{P} admits a KKT point } (x^*,y^*)\in S \text{ with valid Lagrange multipliers } \mu^*\in \R^3 \\
(\text{A}2) &  \text{ the function } (x,y)\mapsto L(x,y,\mu^*) \text{ is convex}
\end{align*}

\noindent First, let's prove that $(\text{A}1)$ holds.

We will use the theorem 8.26 of the lecture notes, as we know by question 1 that LICQ holds at all feasible points. It remains to show that there exists a local minimum of $f$ in $S$.
 
Observe that $S=\{(x,y)\in\R^n\times\R^n \mid h(x,y)=0\}$ is a closed set as a preimage of the closed set $\{0\}\subset \R$ by the continuous function $h$. Moreover, we have $S\subset \{(x, y)\in\R^n\times\R^n \mid h_1(x,y)=0, h_2(x,y)=0\} = \partial B_1(0)\times \partial B_1(0)$, where $B_1(0)=\{z\in\R^n\mid ||z||<1\}$ is the unit ball in $\R^n$. Hence $S$ is bounded. So we deduce that it is compact (as it is closed and bounded in $\R^n\times\R^n=\R^{2n}$).
 
 Now $f$ is continuous on the compact set $S$, thus it must attains its (global) minimum in it, say at a point ($x^*,y^*)$. The theorem 8.26 implies that $(x^*,y^*)$ is a KKT point (as LICQ holds in particular at this point).
 Let $\mu^*\in\R^3$ be valid Lagrange multipliers for $(x^*,y^*)$.\\
 
\noindent Consider now the condition $(\text{A}2)$. It is equivalent to $\begin{bmatrix} A-2\mu^*_1 I_n & \mu^*_3 I_n \\
\mu^*_3 I_n & B-2\mu^*_2 I_n \end{bmatrix}$ being positive semi-definite. Now for this latter condition to be satisfied, we would need information about $\mu^*$. But we can't expect to have those informations before solving the problem, as we need to solve it to find $(x^*,y^*)$.
 

\begin{comment}% en fait c'était un peu de la merde ce que j'avais écrit
Consider $\mu_1^*=\lambda_{\min} (A)/2$, $\mu_2^*=\lambda_{\min} (B)/2$ and $\mu_3^*=0$.\\

\noindent First, consider the condition $(\text{A}2)$. Let $L_{\mu^*}(x,y) = L(x,y,\mu^*)$. By an analogous reasoning as for the previous point, the matrix $M_{\mu^*}=\nabla^2(L_{\mu^*}(x,y)$ is positive semi-definite. Hence by a theorem of the course, $L_{\mu^*}$ is convex. So $(\text{A}2)$ holds for this choice of $\mu^*$.\\

\noindent Now, let's consider $(\text{A}1)$. We will try to find $(x^*, y^*)$ that satisfy this assumption with Lagrange multipliers $\mu^*$ explicited above.\\ 
\noindent For $ (x^*,y^*)\in S$ to be KKT with Lagrange multipliers $\mu^*$, we need: $$h(x^*,y^*)=0 \text{ and }-\nabla f(x^*,y^*)=\sum_{i=1}^3\mu_i\nabla h_i (x^*,y^*).$$
The gradient of $h_1,h_2$ and $h_3$ were already computed in question 1. We can compute easily:
$$\nabla f(x,y) =\begin{bmatrix}
Ax \\ By
\end{bmatrix}$$
Hence $(x^*,y^*)$ and $\mu^*$ need to satisfy
$$-\begin{bmatrix}Ax^* \\ By^*\end{bmatrix}
= \mu_1 \begin{bmatrix} -2x^*\\ \vec 0 \end{bmatrix} + \mu_2 \begin{bmatrix} \vec 0\\ -2y^* \end{bmatrix}+\mu_3 \begin{bmatrix} y^*\\ x^* \end{bmatrix}
$$
This gives the system $\begin{cases} -Ax^* = -2\mu_1 x^* +\mu_3 y^* \\
-By^* = -2\mu_2 y^* +\mu_3 x^*\end{cases}.$ \\
Injecting $\mu^* = \left( \frac{\lambda_{\min} (A)}{2}, \frac{\lambda_{\min} (B)}{2}, 0)\tp\right)$, this gives:
$$\begin{cases} Ax^* = \lambda_{\min}(A) x^* \\
By^* = \lambda_{\min}(B) y^* \end{cases}.$$
So we may take $(x^*,  y^*) = (v_{\min }(A), v_{\min} (B))$, where $v_{\min }(A)$ and $v_{\min }(B)$ are the unit-normed eigenvectors of $\lambda_{\min}(A)$ and $\lambda_{\max}(B)$ respectively. \\
At this point, we need to recall that $(x^*,y^*)$ must belong to the set $S$, or equivalently we must have $h(x^*,y^*)=0$. By taking unit-normed eigenvectors, we ensure that $h_1(x^*,y^*)=0=h_2(x^*,y^*)$. The last condition is $h_3(x^*,y^*) = 0$. By definition of $h_3$, this means $(x^*)\tp y^* = 0$, i.e. $x^*$ and $y^*$ need to be orthogonal in $\R^n$. This is the only assumption we do not know, but observe that as soon as we know it the previous reasoning implies that the assumptions of the strong duality theorem are satisfied.\\

Hence, we can always find $\mu^*\in\R^3$ such that $(\text{A}2)$ is satisfied, but we cannot always ensure that $(\text{A}1)$ is satisfied. One condition that can ensure it however, is that the eigenvectors of $A$ and $B$ corresponding to their smallest eigenvalues are orthogonal. We can not expect to have this before solving the problem if we don't have specific informations about $A$ and $B$ other that them being symmetric.
\end{comment}



\section*{Question 7}

%TODO Préciser que on a écrit quand même, sans vraiment remarquer qu'ils ne voulaient pas les détails?

We will first compute the gradient with respect to $x$. $\nabla_y$ will be done similarly.\\
First of all, we know, by linearity, that 
$$\nabla_x L_{\beta}(x,y,\mu)=\nabla_x f(x,y) + \nabla_x \mu\tp h(x,y)+ \frac{\beta}{2} \nabla_x ||h(x)||^2$$
We will compute each of these expressions:\\

We know that $\nabla_x f(x,y)= Ax$\\

Now for the second one, we can develop $\mu\tp h(x,y)=\mu_1 (1-x\top x)+\mu_2(1-y\tp y) + \mu_3 x\tp y$, so we have:
\begin{align*}
\nabla_x \mu\tp h(x,y)&=\nabla_x (\mu_1 (1-x\top x))+\nabla_x (\mu_2(1-y\tp y)) +\nabla_x ( \mu_3 x\tp y)\\
&=\mu_1 \nabla_x (1-x\top x) + \mu_3 \nabla_x ( x\tp y)\\
&= \mu_1 (-2x) + \mu_3 y\\
&= - 2\mu_1 x+\mu_3 y
\end{align*}
As $\p(x\tp x)=\p \sum_{i=1}^n x_i^2=2x_i$ and  $\p(x\tp y)=\p \sum_{i=1}^n x_i y_i=y_i$\\

Now for the third part we will use the fact that $\nabla||x||^2=2x$ as $x\tp x=||x||^2$ and we've just computed it before. Plus we know the chain rule: $\p f\circ g(x)= \nabla f (g(x)) \cdot \p g(x)$. We can use it to compute our $\nabla$ :
\begin{align*}
\p \frac{\beta}{2} ||h(x,y)||^2&=\beta h(x,y) \cdot \p(h(x,y))\\
\end{align*}
which gives us the formula
\begin{align*}
\nabla_x \frac{\beta}{2} ||h(x,y)||^2&=\beta \nabla_x h(x,y) \cdot  h(x,y) \text{ where } \nabla_x h(x,y) \text{ is a n} \times \text{3 matrix}\\
&=\beta\begin{bmatrix} -2x & \vec 0 & y \end{bmatrix}   \cdot \begin{bmatrix} 1-x\tp x \\ 1-y\tp y\\ x\tp y \end{bmatrix} \\
&=\beta\begin{bmatrix}2(x\tp x-1) x_1+(x\tp y )y_1\\ \vdots \\ 2(x\tp x-1) x_n+(x\tp y )y_n \end{bmatrix}\\
&=\beta \left( 2(x\tp x-1)  x+(x\tp y ) y \right) 
\end{align*}

Putting together our three calculations, we get
\begin{align*}
\nabla_x L_\beta(x,y,\mu)&=Ax - 2\mu_1 x+\mu_3 y+\beta \left( 2(x\tp x-1) x+(x\tp y ) y \right) \\
&=Ax+ 2(\beta (x\tp x-1) - \mu_1) x +(\beta \cdot x\tp y + \mu_3)y
\end{align*}

Similarly, we get
\begin{align*}
\nabla_y L_\beta(x,y,\mu)&=By - 2\mu_2 y+\mu_3 x+\beta \left( 2(y\tp y-1)  y+(x\tp y ) x \right) \\
&=(\beta \cdot x\tp y + \mu_3)x+ By + 2(\beta (y\tp y-1) - \mu_2) y
\end{align*}


\section*{Question 8}

We wrote code that takes as input $z = [x\tp, y\tp]\tp,\ \mu,\ \beta$ (and also $A$ and $B$) and returns $L_\beta(z, \mu)$ and $\nabla_z L_\beta(z, \mu)$.
Our function is named \mcode{LBetaValAndGrad} as it calls the two sub-functions we are showing here: \mcode{LBeta} and \mcode{LBetaGrad}


\lstinputlisting{../LBeta.m}

\lstinputlisting{../LBetaGrad.m}

The first function uses the functions \mcode{f} and \mcode{h} which are a direct implementation of their definition.

\section*{Question 9}

We have used the Matlab \mcode{fminunc} function. We set it to use the 'Quasi-Newton' sub-algorithm as it is the default parameter, it performs as well as Trust-Region in our situation, and it is a little quicker.
We have created a function \mcode{minXY} which calls the precedent function with our choices for the parameters.\\
Here is our implementation.

\lstinputlisting{../minXY.m}

In the 19-th line of the \mcode{main.m}, we defined a function handle which allows us to invoke \mcode{minXY} easily, and which does not output anything in the console:\\
\mcode{silentMinXY = @(mu, beta, z0) minXY(mu, beta, A, B, z0, 0);}\\
This function with $\beta = 1.42$, $\mu = [1, 2, -3]\tp$ and initial guess $z_0 = [1, 0, -1, 2, 1, 1, 2, 0, 1, 2]\tp$  gives after 50 iterations
\begin{lstlisting}
Found x and y are
   -1.3695   -1.2693
   -0.2535    0.9636
   -0.0107   -1.0786
    0.0825    0.7410
    1.4721    0.5569

with value f(x, y) = -28.9565
and LBeta(x, y, mu) = -26.4171
and h(x, y), mu:
   -3.1138    1.0000
   -3.5622    2.0000
    2.3865   -3.0000
\end{lstlisting}

Note that the results would have been little bit different if we were using 'trust-region' as a sub-algorithm for the function \mcode{fminunc}.


\section*{Question 10}
The part of the \mcode{main} running the quadratic penalty method is the following:
\lstinputlisting[firstline=63, lastline=83]{../main.m}

The final iteration leaves:
\begin{lstlisting}
Iteration 9 with beta = 256.
We found x and y:
    0.6036   -0.4636
    0.2996    0.3649
   -0.3370   -0.6272
    0.1038    0.4992
   -0.6591    0.1458

with value f(x, y) = -6.41
   LBeta(x, y, mu) = -6.3694
and h(x, y), beta*h(x, y):
   -0.0128   -3.2785
   -0.0119   -3.0504
   -0.0033   -0.8566

which have norms
    0.0178    4.5593
\end{lstlisting}

We notice that the norm of $h(x, y)$ is divided by two at each iterations, since $\beta h(x, y)$ stays almost constant.
This reassures us that we could hope, as we have seen in the lecture notes, that $h(x_k) \approx \frac{\mu^*}{\beta_k}$. However, we will indeed have a convergence of this sort, as we will see in question 11, but not really to $\mu^*$, as we will see in question 12.\\
We see that after 9 iterations, the points $x$ and $y$ are still \textit{far} from $h(x, y) = 0$. That's why we consider the augmented Lagrangian method.


\section*{Question 11}
The part of the \mcode{main} running the augmented Lagrangian method is the following:
\lstinputlisting[firstline=91, lastline=113]{../main.m}

Note that the only difference is the update of $\mu$ at line 9. Also, we decided not to choose a new $z_0$ randomly, but to reuse the same starting point as with the QPM of question 10.
The final iteration leaves:
\begin{lstlisting}
Iteration 9 with beta = 256.
We found x and y:
    0.5988   -0.4605
    0.2988    0.3626
   -0.3372   -0.6237
    0.1041    0.4965
   -0.6539    0.1447

with value f(x, y) = -6.3288
   LBeta(x, y, mu) = -6.3288
and h(x, y), new mu:
   -0.0000   -3.2774
    0.0000   -3.0515
    0.0000   -0.8582

which have norms
    0.0000    4.5595

Our obtained value for the Dual problem is mu_1 + mu_2 = -6.3288
\end{lstlisting}

This time, $h(x, y)$ goes to 0 really quickly. Moreover, we see that our estimation of $\mu$ quickly stabilizes to a fixed value which is indeed the one $\beta h(x, y)$ was converging to with the quadratic penalty method.

Note that depending on the starting points, the sign of the values may differ. But with all our tests, the numbers were more or less the same.


\section*{Question 12}

Our program finds  
$\begin{pmatrix}
\mu_1\\
\mu_2\\
\mu_3
\end{pmatrix} =
\begin{pmatrix}
-3.2774\\
-3.0515\\
\pm 0.8582
\end{pmatrix}$. The sign of the last value varies, but this is not important for the rest of our calculations.

We know from question 3 that the Lagrangian is\\
$$ L(x, y, \mu) = \dfrac{1}{2}
\begin{bmatrix} x\tp & y\tp\end{bmatrix}
\begin{bmatrix} A-2\mu_1 I_n & \mu_3 I_n \\
\mu_3 I_n & B-2\mu_2 I_n \end{bmatrix}
\begin{bmatrix} x \\ y \end{bmatrix}
+ \mu_1 + \mu_2. $$

We know that for a fixed $\mu$, this function is convex if only if the matrix---that we named $M_\mu$ in question 4---is positive semi-definite.
In our main, the following lines are calculating the minimum eigenvalue of $M_\mu$ and may output a warning in the console.

\lstinputlisting[firstline=134, lastline=140]{../main.m}

As this warning is triggered by our value of $\mu$, we conclude that $L(x, y, \mu)$ is not convex for this $\mu$, and also that $\mu$ is not feasible in (D). That is bad news, since our hope was that $\mu^k$ goes to $\mu^*$ as our algorithm progresses; but instead we have $\mu$, which is the limit\footnote{$\mu$ should be the limit of our calculated sequence $\mu^k$. In practice, we stop at $\mu^9$. Two things motivate this choice. First, the value of $\mu^k$ rapidly converged, and, as the associated value $h(x^k)$ is really close to zero at that point, the value of $\mu^k$ should stay unchanged. But secondly, as $\beta$ increases if we do too much iterations, small calculation residues in $h(x^k)$ will be drastically amplified and will change $\mu^k$ to reach extreme values.}
of $\mu^k$, that is not feasible in (D) and therefore not $\mu^*$. Note that if $\mu$ was feasible, then $\mu_1 + \mu_2 = -6.3288$ would be a lower bound for the value $f(x, y)$ from the weak duality theorem, and we could conclude that our found $(x, y)$ (which reached this value) is a global minimum.
Note that the optimal value for (D) is bounded by $\frac{\lambda_{\min}(A) + \lambda_{\min}(B)}{2} = ??$ , therefore there is no $\mu$ that will show that our found $(x, y)$ is a global minimum. %TODO compléter la valeur, qui doit être calculée par MatLab... (ou Octave, si jamais)

Now we consider the strong duality theorem. We have seen in question 6 that the first assumption holds. However, we can't know if the second one holds before actually solving the problem. We also know that if the theorem does not hold, then there will be a gap between the optimal values for (P) and (D). With our found $(x, y)$, we see that there is a gap with the optimal value of (D), but we can't know if we truly found an optimal point for (P), or if there is a better solution---hiding somewhere and really difficult to find---with no gap and a feasible $\mu^*$, which would make the Lagrangian convex. Thus, we can't know that the theorem holds, nor be sure that it does not hold. However, we are pretty close of a no-gap solution, and the fact that every execution of our algorithm leaves to the same (four, considering axial symmetries) solutions is reassuring in thinking that no better solution exists.\\


TODO rajouter les itérations des qu 10 et 11

\pagebreak
========================================================\\
Le groupe de Léo dit qqch qui ne me convient pas du tout.
\begin{quote}
"We can see that the conditions of the strong duality theorem are not verified.\\
This is very clear when we compute the gap between the primal and the dual."\\
suivit de qqch qui ressemble à\\
\textit{the gap between the theoretical maximum for (D) and our \textbf{local} minimum of (P)  if 0.466.}
\end{quote}
Ils argumentent pas que les conditions sont vérifiées ou pas, ils tentent de montrer que les conséquences ne tiennemt pas. Le truc c'est qu'ils ne peuvent pas savoir si c'est un minimum global ou pas...\\

[ez] ouais bah perso j'ai l'impression qu'il y a bcp de trucs qu'ils ont pas justifié, donc je pense qu'il faut pas se baser entièrement sur leur truc\\
pour le strong duality thm c'est pas une équivalence (i think), donc en soi tu peux dire oui les conditions sont pas vérifiées donc on peut pas appliquer le thm, mais maybe on a égalité (ou dans notre cas on est très proche je crois que c'est ça que tu dis)

\end{document}


\begin{align*}
\p f(x,y)&=\frac{1}{2} \p x\tp A x=\frac{1}{2} \p \sum_{j,k=1}^n x_j A_{ik} x_k=\frac{1}{2} \p \left( \sum_{\substack{j,k=1\\ j,k\neq i}}^n x_j A_{ik} x_k+A_{ii}x_i^2+ x_i \sum_{\substack{j=1 \\ j\neq i}}^n (A_{ij}+A_{ji})x_j \right)\\
&=\frac{1}{2}\left( 2 A_{ii} x_i +  \sum_{\substack{j=1 \\ j\neq i}}^n (A_{ij}+A_{ji})x_j \right)=\frac{1}{2}\left( 2 A_{ii} x_i +  \sum_{\substack{j=1 \\ j\neq i}}^n 2 A_{ij}x_j \right)= \sum_{j=1}^n  A_{ij}x_j =row_i (A) \cdot x
\end{align*}
As $\p f(x,y)$ is the $i$-th element of $\nabla_x f(x,y)$, we get that $\nabla_x f(x,y)= Ax$ \\